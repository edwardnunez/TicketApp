# ğŸ–¥ï¸ GuÃ­a de Uso de JMeter GUI - TicketApp

## ğŸ“‹ Ãndice
- [Tests Disponibles](#tests-disponibles)
- [CÃ³mo Abrir un Test](#cÃ³mo-abrir-un-test)
- [CÃ³mo Ejecutar un Test](#cÃ³mo-ejecutar-un-test)
- [CÃ³mo Ver Resultados](#cÃ³mo-ver-resultados)
- [CÃ³mo Modificar un Test](#cÃ³mo-modificar-un-test)
- [Errores Comunes](#errores-comunes)

---

## ğŸ¯ Tests Disponibles

### 1ï¸âƒ£ Health Check Test
**Archivo:** `1-Health-Check-Test.jmx`

**Â¿QuÃ© hace?**
- Verifica que el Gateway estÃ¡ respondiendo
- 10 usuarios virtuales
- 10 loops = 100 requests totales
- DuraciÃ³n: ~10 segundos

**CuÃ¡ndo usarlo:**
- Primera vez que ejecutas JMeter
- Para verificar que tus servicios estÃ¡n corriendo
- Como prueba rÃ¡pida antes de tests mÃ¡s complejos

---

### 2ï¸âƒ£ Events Load Test
**Archivo:** `2-Events-Load-Test.jmx`

**Â¿QuÃ© hace?**
- Simula usuarios navegando por eventos
- 50 usuarios virtuales
- Cada usuario: Lista eventos â†’ Ve detalles â†’ Ve ubicaciÃ³n
- 5 loops = 750 requests totales
- DuraciÃ³n: ~1-2 minutos

**CuÃ¡ndo usarlo:**
- Probar rendimiento de endpoints pÃºblicos
- Simular trÃ¡fico normal de usuarios
- Detectar problemas de performance en queries de eventos

---

### 3ï¸âƒ£ Authentication Test
**Archivo:** `3-Authentication-Test.jmx`

**Â¿QuÃ© hace?**
- Prueba el sistema de login
- 20 usuarios virtuales hacen login
- Cada usuario valida su token obtenido
- 3 loops = 60 logins totales
- DuraciÃ³n: ~30 segundos

**ConfiguraciÃ³n requerida:**
- Usuario y contraseÃ±a vÃ¡lidos (ver secciÃ³n "ConfiguraciÃ³n")

**CuÃ¡ndo usarlo:**
- Probar el sistema de autenticaciÃ³n bajo carga
- Validar tiempos de respuesta de login
- Verificar que los tokens se generan correctamente

---

### 4ï¸âƒ£ Ticket Purchase Concurrency Test
**Archivo:** `4-Ticket-Purchase-Concurrency-Test.jmx`

**Â¿QuÃ© hace?**
- Simula compra concurrente de tickets
- 30 usuarios virtuales compran al mismo tiempo
- Verifica que no haya overselling
- 2 loops = 60 intentos de compra
- DuraciÃ³n: ~1 minuto

**ConfiguraciÃ³n requerida:**
- Usuario y contraseÃ±a vÃ¡lidos
- ID de evento real (ver secciÃ³n "ConfiguraciÃ³n")

**CuÃ¡ndo usarlo:**
- Probar la lÃ³gica de concurrencia
- Verificar que no se venden asientos duplicados
- Simular "flash sales" o eventos populares

---

## ğŸš€ CÃ³mo Abrir un Test

### Paso 1: Abrir JMeter GUI

```bash
# OpciÃ³n A: Desde PowerShell/CMD
jmeter

# OpciÃ³n B: Doble click en jmeter.bat
# UbicaciÃ³n: C:\Apache\apache-jmeter-5.6.2\bin\jmeter.bat
```

### Paso 2: Abrir el Test

1. En JMeter, ve a: **File > Open** (o `Ctrl + O`)
2. Navega a: `C:\Users\iyanf\OneDrive\Escritorio\ticketapp\jmeter\`
3. Selecciona el test que quieras ejecutar (ej: `1-Health-Check-Test.jmx`)
4. Click **Open**

### Paso 3: Explorar la Estructura

VerÃ¡s una estructura de Ã¡rbol:

```
ğŸ“ Test Plan
  ğŸ“ Thread Group (Grupo de usuarios)
    ğŸŒ HTTP Request 1
    â±ï¸ Timer
    ğŸŒ HTTP Request 2
  ğŸ“Š View Results Tree
  ğŸ“Š Summary Report
  ğŸ“Š Graph Results
```

---

## â–¶ï¸ CÃ³mo Ejecutar un Test

### Antes de Ejecutar

**1. AsegÃºrate que tus servicios estÃ¡n corriendo:**

```bash
# Verificar Gateway
curl http://localhost:8000/health
# Respuesta esperada: {"status":"OK"}
```

**2. Limpia resultados anteriores:**

En JMeter: **Run > Clear All** (o `Ctrl + Shift + E`)

### Ejecutar el Test

**MÃ©todo 1: BotÃ³n Start**
- Click en el botÃ³n verde **Start** (â–¶ï¸) en la barra de herramientas
- O presiona `Ctrl + R`

**MÃ©todo 2: Desde el menÃº**
- Ve a: **Run > Start**

### Durante la EjecuciÃ³n

VerÃ¡s:
- **Contador de threads** (usuarios activos) en la esquina superior derecha
- **Resultados en tiempo real** en los listeners (View Results Tree, Summary Report, etc.)
- **Barra de progreso** (si la has habilitado)

### Detener el Test

- Click en el botÃ³n **Stop** (â¹ï¸) o presiona `Ctrl + .` (punto)
- **Detener inmediatamente**: **Run > Shutdown** (mata todos los threads)

---

## ğŸ“Š CÃ³mo Ver Resultados

### 1. View Results Tree

**DÃ³nde:** Click en "View Results Tree" en el Ã¡rbol del test

**QuÃ© muestra:**
- âœ… Cada request individual (verde = Ã©xito, rojo = error)
- Request data (lo que enviaste)
- Response data (lo que recibiste)
- Headers, cookies, etc.

**CÃ³mo usar:**
```
1. Click en un request en la lista
2. Ve a la pestaÃ±a "Response data"
3. Selecciona el formato apropiado:
   - Text: Para JSON
   - HTML: Para pÃ¡ginas web
   - JSON Path Tester: Para probar extractores
```

**âš ï¸ Advertencia:** NO dejes este listener habilitado en tests grandes (consume mucha memoria)

---

### 2. Summary Report

**DÃ³nde:** Click en "Summary Report" en el Ã¡rbol

**QuÃ© muestra:**

| Columna | Significado |
|---------|-------------|
| **Label** | Nombre del request |
| **# Samples** | Cantidad de requests ejecutados |
| **Average** | Tiempo promedio de respuesta (ms) |
| **Min** | Tiempo mÃ­nimo |
| **Max** | Tiempo mÃ¡ximo |
| **Std. Dev.** | DesviaciÃ³n estÃ¡ndar (consistencia) |
| **Error %** | Porcentaje de errores |
| **Throughput** | Requests por segundo |
| **Received KB/sec** | Datos recibidos |
| **Avg. Bytes** | TamaÃ±o promedio de respuesta |

**InterpretaciÃ³n rÃ¡pida:**
```
Average < 500ms  âœ… Excelente
Average 500-1000ms  âš ï¸ Aceptable
Average > 1000ms  âŒ Necesita optimizaciÃ³n

Error % < 1%  âœ… Bueno
Error % 1-5%  âš ï¸ Revisar
Error % > 5%  âŒ Problemas crÃ­ticos
```

---

### 3. Aggregate Report

**DÃ³nde:** Click en "Aggregate Report" (si estÃ¡ disponible)

**Similar a Summary Report pero ademÃ¡s muestra:**
- **Median (50th percentile):** Tiempo de respuesta del 50% de usuarios
- **90th percentile:** 90% de usuarios tienen este tiempo o menos
- **95th percentile:** Objetivo tÃ­pico en SLAs
- **99th percentile:** Casos extremos

**Ejemplo:**
```
GET /events
  Average: 125ms
  Median: 110ms
  90%: 200ms  â† 90% de usuarios: â‰¤ 200ms
  95%: 250ms  â† 95% de usuarios: â‰¤ 250ms
```

---

### 4. Graph Results

**DÃ³nde:** Click en "Graph Results"

**QuÃ© muestra:**
- GrÃ¡fico de tiempos de respuesta en tiempo real
- LÃ­neas de promedio, mediana, throughput

**InterpretaciÃ³n:**
```
LÃ­nea estable (plana):  âœ… Sistema estable
LÃ­nea ascendente:       âŒ DegradaciÃ³n
Picos ocasionales:      âš ï¸ Investigar causa
```

---

## ğŸ”§ CÃ³mo Modificar un Test

### Cambiar NÃºmero de Usuarios

1. Click derecho en el **Thread Group**
2. Observa el panel derecho
3. Modifica:
   - **Number of Threads (users):** Cantidad de usuarios virtuales
   - **Ramp-up period (seconds):** Tiempo para llegar a todos los usuarios
   - **Loop Count:** CuÃ¡ntas veces cada usuario repite el test

**Ejemplos:**

```
ConfiguraciÃ³n 1: Prueba RÃ¡pida
- Threads: 5
- Ramp-up: 1
- Loops: 10
= 5 usuarios Ã— 10 loops = 50 requests en ~5 segundos

ConfiguraciÃ³n 2: Carga Moderada
- Threads: 50
- Ramp-up: 10
- Loops: 20
= 50 usuarios Ã— 20 loops = 1,000 requests en ~1 minuto

ConfiguraciÃ³n 3: Stress Test
- Threads: 200
- Ramp-up: 30
- Loops: 50
= 200 usuarios Ã— 50 loops = 10,000 requests en ~10 minutos
```

---

### Cambiar Variables (Host, Port, etc.)

1. Click en el **Test Plan** (raÃ­z del Ã¡rbol)
2. En el panel derecho, busca **User Defined Variables**
3. Modifica los valores:

| Variable | DescripciÃ³n | Valor Default |
|----------|-------------|---------------|
| GATEWAY_HOST | Host del gateway | localhost |
| GATEWAY_PORT | Puerto del gateway | 8000 |
| TEST_USERNAME | Usuario para login | testuser |
| TEST_PASSWORD | ContraseÃ±a | password123 |
| TEST_EVENT_ID | ID de evento | (debe configurarse) |

**Ejemplo:**
```
Para probar contra un servidor remoto:
  GATEWAY_HOST = ticketapp.example.com
  GATEWAY_PORT = 443
  Protocol = https (cambiar en cada HTTP Request)
```

---

### Agregar un Nuevo Request

1. Click derecho en el **Thread Group**
2. **Add > Sampler > HTTP Request**
3. Configura el nuevo request:
   - **Name:** Nombre descriptivo
   - **Server Name:** `${GATEWAY_HOST}`
   - **Port Number:** `${GATEWAY_PORT}`
   - **Protocol:** `http`
   - **Method:** GET, POST, PUT, DELETE
   - **Path:** `/api/endpoint`

**Ejemplo - Agregar GET /locations:**

```
Name: GET /locations
Server Name or IP: ${GATEWAY_HOST}
Port Number: ${GATEWAY_PORT}
Path: /locations
Method: GET
```

---

### Agregar Assertions (Validaciones)

1. Click derecho en un **HTTP Request**
2. **Add > Assertions > Response Assertion**
3. Configura:
   - **Field to Test:** Response Code, Response Data, etc.
   - **Pattern Matching Rules:** Contains, Matches, Equals
   - **Patterns to Test:** Valor esperado (ej: `200`)

**Ejemplos comunes:**

```
Assertion 1: Verificar HTTP 200
  Field: Response Code
  Pattern: 200

Assertion 2: Verificar JSON contiene "status"
  Field: Response Data (Text)
  Pattern: "status":"OK"

Assertion 3: Verificar tiempo de respuesta < 500ms
  (Usar Duration Assertion)
  Duration: 500
```

---

### Agregar Timers (Pausas)

Simulan el tiempo que un usuario real tarda en pensar/leer.

1. Click derecho en un **HTTP Request** o **Thread Group**
2. **Add > Timer > Constant Timer**
3. Configura:
   - **Thread Delay:** Tiempo en milisegundos (1000 = 1 segundo)

**Ejemplo:**
```
Usuario real navega eventos:
1. GET /events
2. [TIMER 3000ms] â† Usuario lee la lista
3. GET /events/:id
4. [TIMER 5000ms] â† Usuario decide
5. POST /tickets/purchase
```

---

## ğŸ”‘ ConfiguraciÃ³n Requerida para Tests Avanzados

### Test 3 y 4 Requieren ConfiguraciÃ³n

#### Paso 1: Crear Usuario de Prueba

```bash
# Ejecuta desde PowerShell/CMD
curl -X POST http://localhost:8000/adduser `
  -H "Content-Type: application/json" `
  -d '{
    "name": "Test",
    "surname": "User",
    "username": "testuser",
    "email": "test@example.com",
    "password": "password123"
  }'
```

#### Paso 2: Obtener ID de Evento (para Test 4)

**MÃ©todo 1: Desde MongoDB Compass**
1. Conecta a tu MongoDB
2. Ve a la colecciÃ³n `events`
3. Copia el `_id` de un evento

**MÃ©todo 2: Desde curl**
```bash
curl http://localhost:8000/events
# Copia el "_id" del primer evento en la respuesta
```

#### Paso 3: Configurar Variables en JMeter

1. Abre el test en JMeter
2. Click en **Test Plan**
3. Modifica **User Defined Variables**:
   - `TEST_USERNAME`: testuser
   - `TEST_PASSWORD`: password123
   - `TEST_EVENT_ID`: (pega el ID del evento)

**Ejemplo:**
```
TEST_EVENT_ID = 6786d5a2c5e8f9001a1b2c3d
```

---

## âŒ Errores Comunes

### Error 1: Connection Refused

**SÃ­ntoma:**
```
Response message: Non HTTP response message: Connection refused: connect
```

**Causa:** Los servicios no estÃ¡n corriendo

**SoluciÃ³n:**
```bash
# Verifica servicios
curl http://localhost:8000/health

# Si no responde, inicia servicios
cd C:\Users\iyanf\OneDrive\Escritorio\ticketapp
docker-compose up -d
```

---

### Error 2: HTTP 401 Unauthorized

**SÃ­ntoma:**
```
Response code: 401
Response message: Unauthorized
```

**Causa:** Token invÃ¡lido o expirado

**SoluciÃ³n para Test 3:**
1. Verifica que el usuario existe
2. Verifica username y password en variables
3. Revisa "View Results Tree" > request "POST /login"
4. Verifica que el token se extrajo correctamente

**SoluciÃ³n para Test 4:**
1. Click en "setUp - Login Once"
2. Verifica que se ejecuta primero (es un SetupThreadGroup)
3. Revisa que el token se guardÃ³ en properties

---

### Error 3: HTTP 404 Not Found

**SÃ­ntoma:**
```
Response code: 404
Response message: Not Found
```

**Causa:** Endpoint incorrecto o evento no existe

**SoluciÃ³n:**
```
1. Verifica la URL en el HTTP Request
2. Para Test 4: Verifica que TEST_EVENT_ID es vÃ¡lido
3. Prueba el endpoint manualmente:
   curl http://localhost:8000/events/TU_EVENT_ID
```

---

### Error 4: All Threads Failed

**SÃ­ntoma:**
```
Error % = 100%
Todos los requests fallan
```

**SoluciÃ³n:**
1. Ejecuta **Run > Clear All** antes de cada test
2. Verifica servicios: `curl http://localhost:8000/health`
3. Reduce nÃºmero de threads a 1 para debugging
4. Revisa "View Results Tree" para ver el error exacto

---

### Error 5: No Results Showing

**SÃ­ntoma:**
- Ejecutas el test pero no ves resultados
- Listeners vacÃ­os

**SoluciÃ³n:**
1. Ejecuta **Run > Clear All** ANTES de ejecutar
2. Verifica que los listeners estÃ¡n al nivel correcto:
   ```
   âœ… Correcto:
   ğŸ“ Test Plan
     ğŸ“ Thread Group
       ğŸŒ HTTP Request
     ğŸ“Š Listener (fuera del Thread Group)

   âŒ Incorrecto:
   ğŸ“ Test Plan
     ğŸ“ Thread Group
       ğŸŒ HTTP Request
       ğŸ“Š Listener (dentro puede causar problemas)
   ```

---

## ğŸ’¡ Tips y Trucos

### Tip 1: Ejecutar un Solo Request

Para probar un request especÃ­fico sin ejecutar todo el test:

1. Click derecho en el **HTTP Request**
2. **Disable** todos los otros requests
3. Ejecuta el test
4. Re-**Enable** los otros despuÃ©s

### Tip 2: Ver JSON Formateado

En "View Results Tree":
1. Click en un request
2. PestaÃ±a "Response data"
3. Selector en la parte inferior: Elige **"JSON"**
4. El JSON se mostrarÃ¡ formateado y con colores

### Tip 3: Copiar ConfiguraciÃ³n Entre Tests

1. Click derecho en el elemento (Thread Group, HTTP Request, etc.)
2. **Copy** (`Ctrl + C`)
3. Abre otro test
4. Click derecho donde quieras pegarlo
5. **Paste** (`Ctrl + V`)

### Tip 4: Guardar Resultados

Para guardar resultados en un archivo:

1. Click en un Listener (ej: Summary Report)
2. En el panel inferior, ve a "Filename"
3. Click en **Browse...**
4. Elige ubicaciÃ³n y nombre (ej: `results-2025-01-15.csv`)
5. Ejecuta el test
6. Los resultados se guardan automÃ¡ticamente

### Tip 5: Comparar Resultados

Para comparar rendimiento antes/despuÃ©s de cambios:

```
1. Ejecuta test â†’ Guarda resultados como "baseline.jtl"
2. Haz cambios en tu cÃ³digo
3. Ejecuta test â†’ Guarda resultados como "after-changes.jtl"
4. Compara ambos archivos
```

---

## ğŸ“š Siguientes Pasos

Una vez que domines la GUI:

1. **Aprende CLI:** Para automatizar tests
   ```bash
   jmeter -n -t test.jmx -l results.jtl
   ```

2. **Crea tus propios tests:** Combina y modifica los tests existentes

3. **Integra con CI/CD:** Ejecuta tests automÃ¡ticamente en cada deploy

4. **Explora plugins:** JMeter tiene muchos plugins Ãºtiles
   - Concurrency Thread Group
   - PerfMon (monitoreo de servidor)
   - Dummy Sampler (para debugging)

---

## ğŸ†˜ Ayuda

Si tienes problemas:

1. Revisa [QUICKSTART.md](QUICKSTART.md) para configuraciÃ³n bÃ¡sica
2. Revisa [ANALYZING_RESULTS.md](ANALYZING_RESULTS.md) para interpretar resultados
3. Revisa [test-scenarios.md](test-scenarios.md) para casos avanzados

---

**Â¡Feliz testing! ğŸš€**
